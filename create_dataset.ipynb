{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read presaved dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adv/scores_dataset.csv')\n",
    "df_sampled = pd.read_csv('data/adv/scores_sampled_dataset.csv')\n",
    "# shap_df = pd.read_csv('data/adv/shap_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_datasets=['cifar10','mnist','cifar100']\n",
    "nood_datasets={'cifar10':['cifar100','tin'],\n",
    "               'mnist':['notmnist', 'fashionmnist'],\n",
    "               'cifar100':['cifar10', 'tin']}\n",
    "food_datasets={'cifar10': ['mnist', 'svhn', 'texture', 'places365'],\n",
    "               'mnist':['texture', 'cifar10', 'tin', 'places365'],\n",
    "               'cifar100': ['mnist', 'svhn', 'texture', 'places365']}\n",
    "adv_datasets={'cifar10':['fgsm_0.01', 'fgsm_0.03', 'fgsm_0.09', 'fgsm_0.27', 'pgd_0.01', 'pgd_0.03', 'pgd_0.09', 'pgd_0.27'],\n",
    "              'mnist':['fgsm_0.1', 'fgsm_0.2', 'fgsm_0.3', 'fgsm_0.4', 'pgd_0.1', 'pgd_0.2', 'pgd_0.3', 'pgd_0.4'],\n",
    "              'cifar100':['fgsm_0.01', 'fgsm_0.03', 'fgsm_0.09', 'fgsm_0.27', 'pgd_0.01', 'pgd_0.03', 'pgd_0.09', 'pgd_0.27']}\n",
    "methods=['dice','ebo','godin','gradnorm','gram','klm','knn','mds','mls','msp','odin','react','vim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether all the required files are present\n",
    "for id_dataset in id_datasets:\n",
    "    for method in methods:\n",
    "        for result in os.listdir('results'):\n",
    "            if ((id_dataset in result.split('_')) & (method in result.split('_')) & ('test' in result.split('_'))):\n",
    "                for dataset in [id_dataset]+nood_datasets[id_dataset]+food_datasets[id_dataset]+adv_datasets[id_dataset]:\n",
    "                    if dataset not in [i.split('.npz')[0] for i in os.listdir('results/'+result+'/scores')]:\n",
    "                        print('File not found: '+str(dataset)+' in '+result)\n",
    "                break\n",
    "        else:\n",
    "            print('Folder not found: '+id_dataset+'_'+method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_size=0\n",
    "for id_dataset in id_datasets:\n",
    "    print('ID dataset:',id_dataset)\n",
    "    for i in os.listdir('results'):\n",
    "        if  (('test_ood' in i) and (id_dataset in i.split('_'))):\n",
    "            for j in os.listdir('results/'+i+'/scores'):\n",
    "                conf_size+=np.load('results/'+i+'/scores/'+j)['conf'].size\n",
    "                print(j,np.load('results/'+i+'/scores/'+j)['conf'].size)\n",
    "            break\n",
    "    print(conf_size)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(id_dataset_, dataset_):\n",
    "    if dataset_ == id_dataset_:\n",
    "        return 0\n",
    "    elif dataset_ in nood_datasets[id_dataset_]:\n",
    "        return 1\n",
    "    elif dataset_ in food_datasets[id_dataset_]:\n",
    "        return 2\n",
    "    elif dataset_ in adv_datasets[id_dataset_]:\n",
    "        return 3\n",
    "    else:\n",
    "        print('ERROR id_dataset: '+str(id_dataset_)+', dataset: '+str(dataset_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_array = np.empty(conf_size*len(methods))\n",
    "label_array = np.empty(conf_size*len(methods), dtype=int)\n",
    "dataset_name_array = np.empty(conf_size*len(methods),dtype='U20')\n",
    "method_name_array = np.empty(conf_size*len(methods),dtype='U20')\n",
    "id_dataset_name_array = np.empty(conf_size*len(methods),dtype='U20')\n",
    "\n",
    "fromm = 0\n",
    "too = 0\n",
    "for id_dataset in id_datasets:\n",
    "    for method in methods:\n",
    "        for i in os.listdir('results'):\n",
    "                if  (('test_ood' in i) and (id_dataset in i.split('_')) and (method in i.split('_'))):\n",
    "                    for j in os.listdir('results/'+i+'/scores'):\n",
    "                        dataset_name=j.split('.npz')[0]\n",
    "                        too += np.load('results/'+i+'/scores/'+j)['conf'].size\n",
    "                        scores_array[fromm:too]=np.load('results/'+i+'/scores/'+j)['conf']\n",
    "                        dataset_name_array[fromm:too]=dataset_name\n",
    "                        method_name_array[fromm:too]=method\n",
    "                        id_dataset_name_array[fromm:too]=id_dataset\n",
    "                        label_array[fromm:too]=get_label(id_dataset, dataset_name)\n",
    "                        fromm = too\n",
    "                    break\n",
    "\n",
    "if (fromm!=conf_size*len(methods)):\n",
    "    print('FROMM not equal CONFSIZE!!!', fromm, conf_size*len(methods))\n",
    "\n",
    "\n",
    "df = {'scores': scores_array, 'dataset_name': dataset_name_array, 'method_name': method_name_array, 'id_dataset_name': id_dataset_name_array, 'label': label_array}\n",
    "df = pd.DataFrame(df, columns=['scores', 'dataset_name', 'method_name', 'id_dataset_name', 'label'])\n",
    "df.to_csv('data/adv/scores_dataset.csv')\n",
    "\n",
    "# create new dataframe with same columns\n",
    "df_sampled = pd.DataFrame(columns=['scores', 'dataset_name', 'method_name', 'id_dataset_name', 'label'])\n",
    "\n",
    "\n",
    "#undersample according to id_dataset_name\n",
    "for id_dataset in id_datasets:\n",
    "    for method in methods:\n",
    "        print('ID dataset:',id_dataset, 'method:',method)\n",
    "        #filter by id_dataset_name==id_dataset and dataset_name==id_dataset\n",
    "        df_id = df[(df['id_dataset_name']==id_dataset) & (df['dataset_name']==id_dataset) & (df['method_name']==method)]\n",
    "        #append df_id to df_sampled\n",
    "        df_sampled = pd.concat([df_sampled,df_id])\n",
    "        #get length of df_id\n",
    "        len_id = len(df_id)\n",
    "        print('len_id:',len_id)\n",
    "        #get same length from other datasets\n",
    "        for dataset in nood_datasets[id_dataset]:\n",
    "            df_nood = df[(df['id_dataset_name']==id_dataset) & (df['dataset_name']==dataset) & (df['method_name']==method)].sample(n=len_id//len(nood_datasets[id_dataset]), replace=False, random_state=42)\n",
    "            df_sampled = pd.concat([df_sampled, df_nood])\n",
    "            print('len_nood:',dataset, len(df_nood))\n",
    "        for dataset in food_datasets[id_dataset]:\n",
    "            df_food = df[(df['id_dataset_name']==id_dataset) & (df['dataset_name']==dataset) & (df['method_name']==method)].sample(n=len_id//len(food_datasets[id_dataset]), replace=False, random_state=42)\n",
    "            df_sampled = pd.concat([df_sampled, df_food])\n",
    "            print('len_food:',dataset, len(df_food))\n",
    "        for dataset in adv_datasets[id_dataset]:\n",
    "            df_adv = df[(df['id_dataset_name']==id_dataset) & (df['dataset_name']==dataset) & (df['method_name']==method)].sample(n=len_id//len(adv_datasets[id_dataset]), replace=False, random_state=42)\n",
    "            df_sampled = pd.concat([df_sampled, df_adv])\n",
    "            print('len_adv:',dataset, len(df_adv))\n",
    "        print()\n",
    "df_sampled.to_csv('data/adv/scores_sampled_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df_sampled, facet_col='id_dataset_name', facet_row='method_name', x=\"scores\", y=\"dataset_name\", color='label', height=6000)\n",
    "fig.update_xaxes(matches=None)\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.show()\n",
    "fig.write_html(\"data/adv/boxplot_f.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "chart = alt.Chart(df_sampled).mark_boxplot().encode(\n",
    "    alt.X(\"scores\"),\n",
    "    alt.Y('dataset_name',sort=alt.EncodingSortField(field=\"label\", op=\"min\", order=\"descending\")),\n",
    "    alt.Color('label:N')\n",
    ").facet(\n",
    "    column='id_dataset_name',\n",
    "    row='method_name'\n",
    ").resolve_scale(\n",
    "    x = 'independent',\n",
    "    y = 'independent'\n",
    ").interactive()\n",
    "\n",
    "chart.save('data/adv/chart.html', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011932134628295898,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc557e8fed742819740abbd0ce4d074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007306098937988281,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810929dc99d84a12838480360b6ec1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006760358810424805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67df3d7e80d44b2e94c29c5f0c42eb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007746219635009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbeb2f93c13419f94b7d3d82418a6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006885051727294922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce30dd6bf204abd80de9d70d1c2232f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00579833984375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec12d084931c473db167be7f129a788c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005158901214599609,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b54a1cae7f2480e99c1f15bffed0bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007249593734741211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d7090c80ec4e7f91fb40e7e966cbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010084867477416992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32741dccaeee4468a04149fb8388b3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_df = pd.DataFrame(columns=['methods_used', 'id_dataset_name', 'tot_acc','id_acc', 'food_acc', 'nood_acc', 'adv_acc'])\n",
    "\n",
    "def accuracy_score(y_test, preds):\n",
    "    return np.sum(y_test==preds)/len(y_test)\n",
    "\n",
    "for id_dataset_name in tqdm(id_datasets):\n",
    "    for i in tqdm(range(1,4), leave=False):\n",
    "        for j in tqdm(combinations(methods, i), leave=False):\n",
    "            df_filtered = df_sampled[(df_sampled['method_name'].isin(j)) & (df_sampled['id_dataset_name']==id_dataset_name)]\n",
    "            x = np.empty((len(df_filtered)//len(j),len(j)))\n",
    "            for methodnum, method in enumerate(j):\n",
    "                x[:,methodnum] = df_filtered[df_filtered['method_name']==method]['scores'].to_numpy()\n",
    "            y = df_filtered['label'].to_numpy().reshape(-1,1)[:len(x)]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.2)\n",
    "            bst = XGBClassifier(n_estimators=2, max_depth=3, learning_rate=1, objective='binary:logistic')\n",
    "            bst.fit(X_train, y_train)\n",
    "            preds = bst.predict(X_test).reshape(-1,1)\n",
    "            tot_acc = accuracy_score(y_test, preds)\n",
    "            id_acc = accuracy_score(y_test[y_test==0], preds[y_test==0])\n",
    "            nood_acc = accuracy_score(y_test[y_test==1], preds[y_test==1])\n",
    "            food_acc = accuracy_score(y_test[y_test==2], preds[y_test==2])\n",
    "            adv_acc = accuracy_score(y_test[y_test==3], preds[y_test==3])\n",
    "            shap_df = pd.concat([shap_df, pd.DataFrame([[j, id_dataset_name, tot_acc, id_acc, food_acc, nood_acc, adv_acc]], columns=['methods_used', 'id_dataset_name', 'tot_acc', 'id_acc', 'food_acc', 'nood_acc', 'adv_acc'])], ignore_index=True)\n",
    "\n",
    "shap_df.to_csv('data/adv/shap_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openoodenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
